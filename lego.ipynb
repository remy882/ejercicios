{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM4cWvGV0prcV9DXBvsfoVP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/remy882/ejercicios/blob/main/lego.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torch torchvision torchaudio gradio\n",
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5\n",
        "!pip install -qr requirements.txt\n",
        "#imortamos\n",
        "import torch\n",
        "import gradio as gr\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "#traducción\n",
        "\n",
        "traduccion = {\n",
        "    \"person\": \"persona\",\n",
        "    \"car\": \"coche\",\n",
        "    \"motorcycle\": \"motocicleta\",\n",
        "    \"airplane\": \"avión\",\n",
        "    \"train\": \"tren\",\n",
        "    \"boat\": \"barco\",\n",
        "    \"cat\": \"gato\",\n",
        "    \"dog\": \"perro\",\n",
        "    \"horse\": \"caballo\",\n",
        "    \"sports ball\": \"pelota de futbol\",\n",
        "    \"cell phone\": \"teléfono móvil\",\n",
        "    \"book\": \"libro\",\n",
        "    \"clock\": \"reloj\",\n",
        "}\n",
        "\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
        "#detección\n",
        "\n",
        "def detectar(imagen):\n",
        "    if not isinstance(imagen, Image.Image):\n",
        "        imagen = Image.fromarray(imagen)\n",
        "\n",
        "    results = model(imagen)\n",
        "    # Reemplazar\n",
        "    labels = results.names\n",
        "    translated_labels = {i: traduccion.get(name, name) for i, name in labels.items()}\n",
        "    results.names = translated_labels\n",
        "    # Renderizar\n",
        "    results.render()\n",
        "    img_array = np.array(results.ims[0])\n",
        "    return img_array\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=detectar,\n",
        "    inputs=gr.Image(type=\"pil\", label=\"Sube una imagen\"),\n",
        "    outputs=gr.Image(type=\"numpy\", label=\"Resultado YOLO\"),\n",
        "    title=\"Detector de Objetos YOLO en Español\",\n",
        "    description=\"Sube una imagen y el modelo YOLO detectará objetos automáticamente (nombres en español).\"\n",
        ")\n",
        "\n",
        "demo.launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 924
        },
        "id": "DmNwSpzxMLw3",
        "outputId": "33c266cf-0e7e-453d-918d-f000f82decf9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 17544, done.\u001b[K\n",
            "remote: Counting objects: 100% (42/42), done.\u001b[K\n",
            "remote: Compressing objects: 100% (39/39), done.\u001b[K\n",
            "remote: Total 17544 (delta 25), reused 3 (delta 3), pack-reused 17502 (from 2)\u001b[K\n",
            "Receiving objects: 100% (17544/17544), 16.63 MiB | 18.25 MiB/s, done.\n",
            "Resolving deltas: 100% (12026/12026), done.\n",
            "/content/yolov5/yolov5/yolov5/yolov5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2025-8-20 Python-3.12.11 torch-2.8.0+cu126 CPU\n",
            "\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5s.pt...\n",
            "100%|██████████| 14.1M/14.1M [00:00<00:00, 70.1MB/s]\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
            "Adding AutoShape... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://de45a43b26799a7909.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://de45a43b26799a7909.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sección nueva"
      ],
      "metadata": {
        "id": "9-elm_Z3o_A4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "yMyuqm28onN6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}